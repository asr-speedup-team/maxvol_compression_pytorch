{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monetary-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sealed-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath('../') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../'))\n",
    "if os.path.abspath('../../musco-pytorch-private') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../../musco-pytorch-private'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technical-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from maxvolpy.maxvol import rect_maxvol\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bigger-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxvol_compression.sketch_matrix import RandomSums\n",
    "from maxvol_compression.vmbf import EVBMF, weaken_rank\n",
    "from maxvol_compression.layers import LinearMaxvol\n",
    "from utils.dummy import DummyDatasetCifar10, DummyModelCifar10\n",
    "from musco.pytorch.compressor.layers.conv1d_toeplitz import Conv1Dtoeplitz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-collar",
   "metadata": {},
   "source": [
    "# Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "musical-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "focused-adolescent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.cherniuk/.conda/mark2/lib/python3.7/site-packages/torch/cuda/__init__.py:104: UserWarning: \n",
      "NVIDIA A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA A100-SXM4-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = DummyModelCifar10()\n",
    "model.load_state_dict(torch.load('data/dummy.weights'))\n",
    "cifar10 = DummyDatasetCifar10(batch_size=BATCH_SIZE, data_root='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "freelance-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyModelCifar10(\n",
       "  (conv1): Conv1d(3, 15, kernel_size=(100,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(15, 30, kernel_size=(50,), stride=(1,))\n",
       "  (fc1): Linear(in_features=1350, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=250, bias=True)\n",
       "  (fc3): Linear(in_features=250, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affected-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6571\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "all_ = len(cifar10.testloader) * BATCH_SIZE\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(cifar10.testloader, 0):\n",
    "        inputs, labels = data\n",
    "        _, predicted = torch.max(model(inputs), 1)\n",
    "        correct += (labels == predicted).sum().detach().numpy()\n",
    "        \n",
    "print(f'accuracy: {correct / all_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-harrison",
   "metadata": {},
   "source": [
    "# FC layer maxvol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-supervisor",
   "metadata": {},
   "source": [
    "### computing sketch matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "valued-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomSums(500, 500, keep_original=False)\n",
    "def update_sketchmatrix(self, input, output, alg):\n",
    "    alg.update(torch.flatten(output, 1).cpu().numpy())\n",
    "    \n",
    "handle = model.fc1.register_forward_hook(\n",
    "    partial(update_sketchmatrix, alg=rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "sorted-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "otherwise-version",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 batches completed\n",
      "400 batches completed\n",
      "600 batches completed\n",
      "800 batches completed\n",
      "1000 batches completed\n",
      "1200 batches completed\n",
      "1400 batches completed\n",
      "1600 batches completed\n",
      "1800 batches completed\n",
      "2000 batches completed\n",
      "2200 batches completed\n",
      "2400 batches completed\n",
      "2600 batches completed\n",
      "2800 batches completed\n",
      "3000 batches completed\n",
      "3200 batches completed\n",
      "3400 batches completed\n",
      "3600 batches completed\n",
      "3800 batches completed\n",
      "4000 batches completed\n",
      "4200 batches completed\n",
      "4400 batches completed\n",
      "4600 batches completed\n",
      "4800 batches completed\n",
      "5000 batches completed\n",
      "CPU times: user 5min 48s, sys: 18.4 s, total: 6min 6s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch,_) in enumerate(cifar10.trainloader, 1):\n",
    "    with torch.no_grad():\n",
    "        _ = model(batch)\n",
    "    if i % 200 == 0: print(f'{i} batches completed')\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-conflict",
   "metadata": {},
   "source": [
    "### EVBMF rank estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cordless-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sigma, Vt = np.linalg.svd(rs.sketch_matrix, full_matrices=False)\n",
    "_, vbmf_s, _, vbmf_post = EVBMF(None, pretrained_svd=(None, sigma, Vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cathedral-boost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 113)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbmf_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "operating-chambers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = weaken_rank(rank=min(*Vt.shape), extreme_rank =len(vbmf_s), weakenen_factor=1.0)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-cameroon",
   "metadata": {},
   "source": [
    "### rect-maxvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "technical-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 113)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = Vt.T[:, :rank]\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "regional-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 214 ms, sys: 125 ms, total: 339 ms\n",
      "Wall time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idxs, _ = rect_maxvol(V, maxK=int(1.7*min(*V.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stopped-possibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 ms, sys: 27 Âµs, total: 21 ms\n",
      "Wall time: 34.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "invSV = np.linalg.pinv(V[idxs, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "applicable-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113, 192), (500, 113))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invSV.shape, V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dublin",
   "metadata": {},
   "source": [
    "### compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "regulated-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1 = LinearMaxvol(model.fc1, idxs, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "atomic-antarctica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyModelCifar10(\n",
       "  (conv1): Conv1d(3, 15, kernel_size=(100,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(15, 30, kernel_size=(50,), stride=(1,))\n",
       "  (fc1): LinearMaxvol(in_features=1350, out_features=500, bias=True, idxs_len=192)\n",
       "  (fc2): Linear(in_features=500, out_features=250, bias=True)\n",
       "  (fc3): Linear(in_features=250, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-bermuda",
   "metadata": {},
   "source": [
    "### accuracy drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "velvet-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6457\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "all_ = len(cifar10.testloader) * BATCH_SIZE\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(cifar10.testloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        _, predicted = torch.max(model(inputs), 1)\n",
    "        correct += (labels == predicted).sum().detach().numpy()\n",
    "        \n",
    "print(f'accuracy: {correct / all_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-madonna",
   "metadata": {},
   "source": [
    "# Conv1d layer maxvol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-salad",
   "metadata": {},
   "source": [
    "### computing sketch matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pressed-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomSums(500, 13875, keep_original=False)\n",
    "def update_sketchmatrix(self, input, output, alg):\n",
    "    alg.update(torch.flatten(output, 1).cpu().numpy())\n",
    "    \n",
    "handle = model.conv1.register_forward_hook(\n",
    "    partial(update_sketchmatrix, alg=rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "administrative-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "stone-xerox",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 batches completed\n",
      "400 batches completed\n",
      "600 batches completed\n",
      "800 batches completed\n",
      "1000 batches completed\n",
      "1200 batches completed\n",
      "1400 batches completed\n",
      "1600 batches completed\n",
      "1800 batches completed\n",
      "2000 batches completed\n",
      "2200 batches completed\n",
      "2400 batches completed\n",
      "2600 batches completed\n",
      "2800 batches completed\n",
      "3000 batches completed\n",
      "3200 batches completed\n",
      "3400 batches completed\n",
      "3600 batches completed\n",
      "3800 batches completed\n",
      "4000 batches completed\n",
      "4200 batches completed\n",
      "4400 batches completed\n",
      "4600 batches completed\n",
      "4800 batches completed\n",
      "5000 batches completed\n",
      "CPU times: user 13min 53s, sys: 7min 48s, total: 21min 41s\n",
      "Wall time: 16min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch,_) in enumerate(cifar10.trainloader, 1):\n",
    "    with torch.no_grad():\n",
    "        _ = model(batch)\n",
    "    if i % 200 == 0: print(f'{i} batches completed')\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ongoing-messenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sketch matrix was saved to data/conv1_sketch_matrix.npy\n"
     ]
    }
   ],
   "source": [
    "rs.save('data/conv1_sketch_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-safety",
   "metadata": {},
   "source": [
    "### EVBMF rank estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distributed-thursday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sketch matrix was loaded from data/conv1_sketch_matrix.npy\n"
     ]
    }
   ],
   "source": [
    "rs = RandomSums(500, 13875, keep_original=True)\n",
    "rs.load('data/conv1_sketch_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "likely-mechanics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.84 s, sys: 1.02 s, total: 2.86 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, sigma, Vt = np.linalg.svd(rs.sketch_matrix, full_matrices=False)\n",
    "_, vbmf_s, _, vbmf_post = EVBMF(None, pretrained_svd=(None, sigma, Vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continent-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 404)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbmf_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "applied-relationship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = weaken_rank(rank=min(*Vt.shape), extreme_rank =len(vbmf_s), weakenen_factor=1.0)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-sight",
   "metadata": {},
   "source": [
    "### rect-maxvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "floating-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13875, 404)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = Vt.T[:, :rank]\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "double-peoples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 11 ms, total: 1.13 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idxs, _ = rect_maxvol(V, maxK=int(1.7*min(*V.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alert-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 93.7 ms, sys: 64 ms, total: 158 ms\n",
      "Wall time: 81.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "invSV = np.linalg.pinv(V[idxs, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hungry-encoding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 686), (13875, 404))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invSV.shape, V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-palmer",
   "metadata": {},
   "source": [
    "### compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sized-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_tplz = Conv1Dtoeplitz(model.conv1, (BATCH_SIZE, 3, 1024))\n",
    "conv1d_tplz.dense_layer = LinearMaxvol(conv1d_tplz.dense_layer, idxs, V)\n",
    "model.conv1 = conv1d_tplz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "decimal-subject",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([686])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_tplz.dense_layer.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "conscious-realtor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6276\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "all_ = len(cifar10.testloader) * BATCH_SIZE\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(cifar10.testloader, 0):\n",
    "        inputs, labels = data\n",
    "        _, predicted = torch.max(model(inputs), 1)\n",
    "        correct += (labels == predicted).sum().detach().numpy()\n",
    "        \n",
    "print(f'accuracy: {correct / all_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-directive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark2",
   "language": "python",
   "name": "mark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

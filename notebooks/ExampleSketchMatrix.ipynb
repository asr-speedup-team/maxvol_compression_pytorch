{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath('../') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxvol_compression.sketch_matrix import FastFrequentDirections, RandomSums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDatasetCifar10:\n",
    "    def __init__(self, batch_size=4, data_root='./data'):\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        self.batch_size = batch_size\n",
    "        self.trainset = torchvision.datasets.CIFAR10(root=data_root, \n",
    "                                                     train=True,\n",
    "                                                     download=True, \n",
    "                                                     transform=self.transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(self.trainset, \n",
    "                                                       batch_size=self.batch_size,\n",
    "                                                       shuffle=True, \n",
    "                                                       drop_last=True,\n",
    "                                                       num_workers=2)\n",
    "        self.testset = torchvision.datasets.CIFAR10(root=data_root, \n",
    "                                                    train=False,\n",
    "                                                    download=True, \n",
    "                                                    transform=self.transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(self.testset, \n",
    "                                                      batch_size=self.batch_size,\n",
    "                                                      shuffle=False, \n",
    "                                                      drop_last=True,\n",
    "                                                      num_workers=2)\n",
    "        self.classes = np.array(['plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModelCifar10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_classes = 10\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyModelCifar10()\n",
    "cifar10 = DummyDatasetCifar10(batch_size=BATCH_SIZE, data_root='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run to compute bounds\n",
    "fds = FastFrequentDirections(150, 400, keep_original=True)\n",
    "def update_sketchmatrix(self, input, output, alg):\n",
    "    batch_size = input[0].shape[0]\n",
    "    alg.update(input[0].view(batch_size, -1).cpu().numpy())\n",
    "    \n",
    "handle = model.fc1.register_forward_hook(\n",
    "    partial(update_sketchmatrix, alg=fds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, (batch,_) in enumerate(cifar10.testloader, 1):\n",
    "    with torch.no_grad():\n",
    "        _ = model(batch)\n",
    "    if i % 200 == 0: print(f'{i} batches completed')\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "fds.sketch_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "fds.compute_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run to compute bounds\n",
    "rs = RandomSums(150, 400, keep_original=True)\n",
    "def update_sketchmatrix(self, input, output, alg):\n",
    "    batch_size = input[0].shape[0]\n",
    "    alg.update(input[0].view(batch_size, -1).cpu().numpy())\n",
    "    \n",
    "handle = model.fc1.register_forward_hook(\n",
    "    partial(update_sketchmatrix, alg=rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, (batch,_) in enumerate(cifar10.testloader, 1):\n",
    "    with torch.no_grad():\n",
    "        _ = model(batch)\n",
    "    if i % 200 == 0: print(f'{i} batches completed')\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.sketch_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.compute_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-detective",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark1",
   "language": "python",
   "name": "mark1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
